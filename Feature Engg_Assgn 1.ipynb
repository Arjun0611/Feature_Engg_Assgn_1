{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a028a8f9-be8c-4f4b-b91f-706c44741af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b32f293-3851-4d26-99a0-bade2b1dc984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values in a dataset:\n",
    "\n",
    "# Are absent or undefined data points for one or more variables or observations.\n",
    "# Can compromise data integrity\n",
    "# Reduce statistical power and bias results.\n",
    "# Challenge ML algorithms that cannot handle missing values, leading to errors during model training and evaluation.\n",
    "# Require proper handling.\n",
    "\n",
    "# Algorithms unaffected by missing values:\n",
    "\n",
    "# Decision Trees\n",
    "# Random Forest\n",
    "# K-Nearest Neighbors\n",
    "# Naive Bayes\n",
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdeff72e-6d59-48be-800d-75391ad9697a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2.\n",
    "\n",
    "# Handling missing data is crucial in data preprocessing. Here are some common techniques and Python examples for each:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "494800d8-e386-40c3-ad12-9d560a101113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deletion - Removing rows or columns with missing values.\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bb4ad2e-5d50-4f1b-a595-a33cd5dc5874",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'A':[1,2,np.nan,4], 'B':[5,np.nan,7,8]}\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7510fa01-e060-4f5b-b7af-80a03138ebfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B\n",
      "0  1.0  5.0\n",
      "3  4.0  8.0\n"
     ]
    }
   ],
   "source": [
    "df_dropped = df.dropna()\n",
    "print(df_dropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28363c62-8a9d-4ec3-afd8-f30c05215ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputation - Replacing missing values with statistical measures.\n",
    "\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c7eac8e-688b-4cd5-92f6-3e2f0cf9b69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'A':[1,2,np.nan,4], 'B':[5,np.nan,7,8]}\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc8648f5-3dcb-49d1-b08d-ee9e4cca9cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          A         B\n",
      "0  1.000000  5.000000\n",
      "1  2.000000  6.666667\n",
      "2  2.333333  7.000000\n",
      "3  4.000000  8.000000\n"
     ]
    }
   ],
   "source": [
    "imputer = SimpleImputer(strategy='mean')\n",
    "df_imputed = imputer.fit_transform(df)\n",
    "df_imputed = pd.DataFrame(df_imputed,columns=df.columns)\n",
    "print(df_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce7ab980-396c-4d8f-81fa-ead0fd24e68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward Fill and Backward Fill - Propagating the last valid observation forward or using the next valid observation backward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a63dc005-3691-4fe9-9409-e4fc0c4b8970",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'A':[1,2,np.nan,4], 'B':[5,np.nan,7,8]}\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d54ecf3b-da9b-44a8-90a7-5e60f6165d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ffill = df.fillna(method='ffill')\n",
    "df_bfill = df.fillna(method='bfill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee7f9111-97d4-4118-bf11-bc1177cdbc66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B\n",
      "0  1.0  5.0\n",
      "1  2.0  5.0\n",
      "2  2.0  7.0\n",
      "3  4.0  8.0\n",
      "     A    B\n",
      "0  1.0  5.0\n",
      "1  2.0  7.0\n",
      "2  4.0  7.0\n",
      "3  4.0  8.0\n"
     ]
    }
   ],
   "source": [
    "print(df_ffill)\n",
    "print(df_bfill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7b63f41e-e3b8-456e-843a-7264919025f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolation - Estimating missing values based on existing data points.\n",
    "\n",
    "data = {'A':[1,2,np.nan,4], 'B':[5,np.nan,7,8]}\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cdb24a6a-d10c-44fb-b7a2-fc0c838e9126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B\n",
      "0  1.0  5.0\n",
      "1  2.0  6.0\n",
      "2  3.0  7.0\n",
      "3  4.0  8.0\n"
     ]
    }
   ],
   "source": [
    "df_interpolated = df.interpolate()\n",
    "print(df_interpolated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "54bd4a45-4dd4-4df8-8107-d3c54af9948b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1c11871c-681e-40b8-b281-31a0dbe5d657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imbalanced Data: Refers to unequal class distribution in a classification problem.\n",
    "# Bias in Model: Imbalanced data leads to model bias towards the majority class.\n",
    "# Misclassification: Minority classes suffer higher misclassification rates.\n",
    "# Ineffective Learning: Models struggle to learn patterns in minority classes.\n",
    "# Loss of information: Valuable information in minority classes is neglected.\n",
    "# Unfair Model: Can result in unfair or biased predications in applications like fraud detection or medical diagnosis.\n",
    "# Poor Generalization: Models may have trouble generalizing to new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "472de5a4-ab56-440f-9432-a29dde4d3d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q4.\n",
    "\n",
    "# Up-sampling: Increasing the number of instances in the minority class by duplicating or creating synthetic examples.\n",
    "\n",
    "# Down-sampling: Reducing the number of instances in the majority class by randomly removing examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8a570299-7981-44f9-a019-d31502e04049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Up-sampling Example:\n",
    "\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "345eb23c-cbb1-46dc-b0e2-510b759328da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   feature1  target\n",
      "0         1       0\n",
      "2         3       0\n",
      "3         4       0\n",
      "5         6       0\n",
      "6         7       0\n",
      "8         9       0\n",
      "7         8       1\n",
      "1         2       1\n",
      "7         8       1\n",
      "7         8       1\n",
      "1         2       1\n",
      "1         2       1\n"
     ]
    }
   ],
   "source": [
    "data = pd.DataFrame({\n",
    "    \n",
    "    'feature1': [1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "    'target': [0, 1, 0, 0, 1, 0, 0, 1, 0]\n",
    "})\n",
    "\n",
    "minority_class = data[data['target'] == 1]\n",
    "majority_class = data[data['target'] == 0]\n",
    "\n",
    "minority_upsampled = resample(minority_class, replace=True,n_samples=len(majority_class),random_state=42)\n",
    "\n",
    "balanced_data = pd.concat([majority_class, minority_upsampled])\n",
    "print(balanced_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4a470d81-17de-43ed-8f45-759bd424089b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   feature1  target\n",
      "1         2       1\n",
      "4         5       1\n",
      "7         8       1\n",
      "0         1       0\n",
      "2         3       0\n",
      "8         9       0\n"
     ]
    }
   ],
   "source": [
    "# Down-sampling Example:\n",
    "\n",
    "data = pd.DataFrame({\n",
    "    'feature1': [1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "    'target': [0, 1, 0, 0, 1, 0, 0, 1, 0]\n",
    "})\n",
    "\n",
    "# Separate minority and majority classes\n",
    "minority_class = data[data['target'] == 1]\n",
    "majority_class = data[data['target'] == 0]\n",
    "\n",
    "# Down-sample the majority class\n",
    "majority_downsampled = resample(majority_class, replace=False, n_samples=len(minority_class), random_state=42)\n",
    "\n",
    "# Combine the down-sampled majority class with the minority class\n",
    "balanced_data = pd.concat([minority_class, majority_downsampled])\n",
    "\n",
    "print(balanced_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "763e2849-7e1e-4e82-b3b5-63db39f80d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q5.\n",
    "\n",
    "# Data Augmentation: Technique to expand a dataset by applying transformations to existing data.\n",
    "\n",
    "# SMOTE: Synthetically generates samples for minority class in imbalanced datasets.\n",
    "\n",
    "# Purpose: Balancing class distribution in classification problems.\n",
    "\n",
    "# How It Works: Interpolates between minority class samples and their nearest neighbors.\n",
    "\n",
    "# Example: Balancing 100 minority samples with 900 majority samples using a 1:1 ratio.\n",
    "\n",
    "# Benefits: Mitigates class imbalance, reduces overfitting to majority class, improves generalization for minority class.\n",
    "\n",
    "# Considerations: Use with caution, as agressive oversampling can introduce noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d78f50d8-f10d-4d39-a272-69d40309b2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q6.\n",
    "\n",
    "# Outliers: Data points significantly different from other obaservations.\n",
    "# Importance of Handling:\n",
    "# Affect statistical measures and assumptions.\n",
    "# Distort model accuracy and generalization.\n",
    "# May indicate errors or rare events.\n",
    "\n",
    "# Methods to Handle:\n",
    "# Identify and remove outliers.\n",
    "# Transform data to be less sensitive to outliers.\n",
    "# Use robust statistical techniques.\n",
    "# Treat outliers as a separate class\n",
    "\n",
    "# Impact on Analysis:\n",
    "# Outliers can skew results, lead to incorrect conclusions, and affect model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d480b296-db8c-4438-bfd4-6f99b1745219",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q7.\n",
    "# Here are the techniques to handle missing data in customer data analysis with concise explanations:\n",
    "# Data Imputation: Fill missing values with mean, median, or mode.\n",
    "# Forward or Backward Fill: Use neighboring values for time-series data.\n",
    "# Interpolation: Estimate missing values based on data trends.\n",
    "# Multiple Imputation: Generate and analyze multiple imputed datasets.\n",
    "# Deletion: Listwise: Remove rows with any missing values.; Pairwise: Analyze data as-is, ignoring missing values for specific calculations.\n",
    "# Predictive Modeling: Use ML to predict missing values.\n",
    "# Domain-Specific Methods: Apply industry knowledge.\n",
    "# Missing Data Indicator: Add a binary column to flag missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5a17bae7-e3ac-4adb-bf06-16762f8c2dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q8.\n",
    "\n",
    "# Visual Inspection: Use data visualizations like heatmaps to spot patterns in missing data.\n",
    "# Statistical Testing: Apply statistical tests (e.g., chi-square, t-tests) to identify relationships with other variables.\n",
    "# Domain Expertise: Seek insights from domain experts who may understand the reasons behind missing data.\n",
    "# Exploratory Data Analysis (EDA): Conduct comprehensive EDA to uncover potential patterns or trends.\n",
    "# Imputation Methods: Test various imputation techniques, observing which ones work best, indicating data patterns.\n",
    "# Machine Learning Models: Train models to predict missing values; good performance suggests patterns.\n",
    "# Time-Series Consideration: Analyze time-related or event-based patterns in time-series data.\n",
    "# Surveys or Interviews: Gather additional information or insights from data sources or surveys to explain missing data.\n",
    "# Correlation Analysis: Investigate correlations between variables with missing data and others; strong correlations may reveal patterns.\n",
    "# Missing Data Indicators: Create binary indicators (1 for missing, 0 for not) and study their relationships with other variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f1bbb15c-2a06-4127-ad69-e345363db869",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q9.\n",
    "\n",
    "# Here are a few effective strategies to evaluate the performance of a machine learning model on an imbalanced dataset in a medical diagnosis project:\n",
    "\n",
    "# Ensemble Models: Employ ensemble methods like Random Forests or Gradient Boosting, which handle class imbalance well.\n",
    "\n",
    "# Resampling: Either oversample the minority class (up-sampling) or undersample the majority class (down-sampling) to balance the class distribution.\n",
    "\n",
    "# Synthetic Data Generation: Use techniques like Synthetic Minority Over-sampling Technique (SMOTE) to create synthetic samples of the minority class.\n",
    "\n",
    "# Anomaly Detection: Treat the minority class as anomalies and apply anomaly detection algorithms.\n",
    "\n",
    "# Cost-sensitive Learning: Adjust the misclassification costs to penalize errors on the minority class more heavily.\n",
    "\n",
    "# Cross-Validation: Perform cross-validation with stratified sampling to ensure representative splits during training and evaluation.\n",
    "\n",
    "# Algorithm Selection: Choose algorithms that are less sensitive to class imbalance, such as Support Vector Machines (SVM) with class weights.\n",
    "\n",
    "# Collect More Data: If possible, collect more data for the minority class to balance the dataset.\n",
    "\n",
    "# Domain Knowledge: Leverage domain knowledge to inform feature engineering or model selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "793abbe8-f12d-4c4a-89ca-f080a213e5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q10.\n",
    "\n",
    "# To balance an unbalanced dataset with a majority class (e.g., satisfied customers) and a minority class (e.g., unsatisfied customers) through down-sampling, you can employ several methods:\n",
    "\n",
    "# Random Down-Sampling: Randomly select a subset of the majority class samples to match the size of the minority class.\n",
    "\n",
    "# Cluster-Based Down-Sampling: Use clustering techniques to group similar samples from the majority class, then randomly select one sample from each cluster.\n",
    "\n",
    "# Edited Nearest Neighbors (ENN): Remove majority class samples whose class label differs from most of their k-nearest neighbors.\n",
    "\n",
    "# NearMiss: Select majority class samples that are closest to the minority class samples based on specific distance metrics.\n",
    "\n",
    "# CNN (Condensed Nearest Neighbors): Iteratively identify and remove redundant majority class samples while preserving the boundary information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c797ec1f-a94e-417a-b11d-94cfab68116f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q11.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
